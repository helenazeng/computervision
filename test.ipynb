{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pylab\n",
    "import mahotas as mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color = []\n",
    "mask = []\n",
    "normal = []\n",
    "for i in range(0,20000):\n",
    "    color.append(mh.imread('project/eecs442challenge/train/color/'+str(i)+'.png'))\n",
    "    mask.append(mh.imread('project/eecs442challenge/train/mask/'+str(i)+'.png'))\n",
    "    normal.append(mh.imread('project/eecs442challenge/train/normal/'+str(i)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = color[0]\n",
    "pylab.imshow(test)\n",
    "pylab.show()\n",
    "print(color[100].shape)\n",
    "mh.imsave(str(i)+'.png',test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(color))\n",
    "print(len(normal))\n",
    "\n",
    "print(color[0].shape)\n",
    "print(normal[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m30834.54688\u001b[0m\u001b[0m | time: 210.703s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 001 | loss: 30834.54688 - acc: 0.0092 -- iter: 00180/20000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# Data loading and preprocessing\n",
    "#import tflearn.datasets.oxflower17 as oxflower17\n",
    "#X, Y = oxflower17.load_data(one_hot=True)\n",
    "X = color\n",
    "Y = normal\n",
    "\n",
    "# TODO: apply masks\n",
    "\n",
    "# Building 'VGG Network'\n",
    "network = input_data(shape=[None, 128, 128, 3])\n",
    "\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = conv_2d(network, 64, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = conv_2d(network, 128, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = conv_2d(network, 256, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = conv_2d(network, 512, 3, activation='relu')\n",
    "network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "network = fully_connected(network, 4096, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 4096, activation='relu')\n",
    "network = dropout(network, 0.5)\n",
    "network = fully_connected(network, 128*128*3, activation='softmax')\n",
    "network = tflearn.reshape(network, [-1, 128, 128, 3])\n",
    "\n",
    "network = regression(network, optimizer='momentum',\n",
    "                     loss='mean_square',\n",
    "                     learning_rate=0.001)\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(network, checkpoint_path='model_vgg',\n",
    "                    max_checkpoints=1, tensorboard_verbose=2)\n",
    "# tensorboard_verbose from 0-3 3: Loss, Accuracy, Gradients, Weights, Activations, Sparsity.\n",
    "# check point default = none\n",
    "model.fit(X, Y, n_epoch=3, shuffle=True,\n",
    "          show_metric=True, batch_size=20, snapshot_step=500,\n",
    "          snapshot_epoch=False, run_id='project_test')\n",
    "#plt.imshow(mh.as_rgb(red, green, blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "# --------------------------------------\n",
    "# High-Level API: Using TFLearn wrappers\n",
    "# --------------------------------------\n",
    "\n",
    "# Using MNIST Dataset\n",
    "import tflearn.datasets.mnist as mnist\n",
    "mnist_data = mnist.read_data_sets(one_hot=True)\n",
    "\n",
    "# User defined placeholders\n",
    "with tf.Graph().as_default():\n",
    "    # Placeholders for data and labels\n",
    "    X = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=(None, 10), dtype=tf.float32)\n",
    "\n",
    "    net = tf.reshape(X, [-1, 28, 28, 1])\n",
    "\n",
    "    # Using TFLearn wrappers for network building\n",
    "    net = tflearn.conv_2d(net, 32, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.conv_2d(net, 64, 3, activation='relu')\n",
    "    net = tflearn.max_pool_2d(net, 2)\n",
    "    net = tflearn.local_response_normalization(net)\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 128, activation='tanh')\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 256, activation='tanh')\n",
    "    net = tflearn.dropout(net, 0.8)\n",
    "    net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "\n",
    "    # Defining other ops using Tensorflow\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net, Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        batch_size = 128\n",
    "        for epoch in range(2): # 2 epochs\n",
    "            avg_cost = 0.\n",
    "            total_batch = int(mnist_data.train.num_examples/batch_size)\n",
    "            for i in range(total_batch):\n",
    "                batch_xs, batch_ys = mnist_data.train.next_batch(batch_size)\n",
    "                sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "                cost = sess.run(loss, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "                avg_cost += cost/total_batch\n",
    "                if i % 20 == 0:\n",
    "                    print(\"Epoch:\", '%03d' % (epoch+1), \"Step:\", '%03d' % i,\n",
    "                          \"Loss:\", str(cost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
